{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np \n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","from scipy.spatial import distance\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["DataSet = pd.DataFrame()\n","DataSet = pd.read_csv(\"/kaggle/input/diabetes/diabetes.csv\")\n","DataSet.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for column in DataSet.columns[1:-3]:\n","    DataSet[column].replace(0,np.NaN, inplace=True)\n","    DataSet[column].fillna(round(DataSet[column].mean(skipna=True)), inplace=True)\n","DataSet.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","X = DataSet.iloc[:, :8]\n","y = DataSet.iloc[:, 8:]\n","# Split data into 20% for testing and 80% for training\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def distance_with_all_train_Points(X_train, X_test):\n","    eculidean_distance = {}\n","    for data_point in X_test.itertuples():\n","        for point in X_train.itertuples():\n","            eculidean_distance[tuple([list(data_point)[0],list(point)[0]])] = distance.euclidean(list(data_point)[1:], list(point)[1:])\n","    return eculidean_distance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","#program\n","def k_nearest_neighbors(eculidean_distance, X_test, y, k):\n","\n","        all_neighbours = {}\n","        Output_labels = []\n","        for data_point in X_test.itertuples():\n","            for key, value in eculidean_distance.items():\n","                if key[0] == list(data_point)[0]:\n","                    all_neighbours[key] = value\n","                else:\n","                    continue\n","            i, yes, no = 0, 0, 0\n","            for item in sorted(all_neighbours.items(), key = lambda x: x[1]):\n","                if i < k:\n","                    if(y.iloc[item[0][1]][\"Outcome\"] == 1):\n","                        yes += 1\n","                    else:\n","                        no += 1\n","                    i += 1\n","        # Till this point, we know that how much nearest neighbours have label of one and label of 0 for having diabaties or not.\n","        # On the basis of this we'll assign label to new data Point.\n","            if(yes > no):\n","                Output_labels.append(1)\n","            else:\n","                Output_labels.append(0)\n","            all_neighbours.clear()\n","            \n","        return Output_labels\n","#program end\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","eculidean_distance = distance_with_all_train_Points(X_train, X_test)\n","Output_labels = k_nearest_neighbors(eculidean_distance, X_test, y, 5)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["neighbor = KNeighborsClassifier(n_neighbors=5)\n","neighbor.fit(X_train, np.array(y_train).ravel())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","y_pred = neighbor.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","neighbor.score(X_test, Output_labels)"]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
